{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open in [nbviewer](http://nbviewer.jupyter.org/github/luiarthur/GLM_AMS274/blob/master/notes/notes10.ipynb)\n",
    "$\n",
    "% Latex definitions\n",
    "% note: Ctrl-shfit-p for shortcuts menu\n",
    "\\newcommand{\\iid}{\\overset{iid}{\\sim}}\n",
    "\\newcommand{\\ind}{\\overset{ind}{\\sim}}\n",
    "\\newcommand{\\p}[1]{\\left(#1\\right)}\n",
    "\\newcommand{\\bk}[1]{\\left[#1\\right]}\n",
    "\\newcommand{\\bc}[1]{ \\left\\{#1\\right\\} }\n",
    "\\newcommand{\\abs}[1]{ \\left|#1\\right| }\n",
    "\\newcommand{\\norm}[1]{ \\left|\\left|#1\\right|\\right| }\n",
    "\\newcommand{\\E}{ \\text{E} }\n",
    "\\newcommand{\\N}{ \\mathcal N }\n",
    "\\newcommand{\\ds}{ \\displaystyle }\n",
    "\\newcommand{\\R}{ \\mathbb{R} }\n",
    "\\newcommand{\\suml}{ \\sum_{i=1}^n }\n",
    "\\newcommand{\\prodl}{ \\prod_{i=1}^n }\n",
    "\\newcommand{\\overunderset}[3]{\\overset{#1}{\\underset{#2}{#3}}}\n",
    "\\newcommand{\\asym}{\\overset{\\cdot}{\\sim}}\n",
    "\\newcommand{\\given}{\\bigg |}\n",
    "\\newcommand{\\M}{\\mathcal{M}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Binomial Regression Models (GLM)\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "y_i | \\pi_i &\\ind Bin(m_i,\\pi_i), ~ i=1,...,n \\\\\n",
    "\\pi_i &\\sim g^{-1}(x_i^T\\beta), ~ \\pi_i = \\frac{1}{1+\\exp(-\\theta_i)} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "## Link Functions\n",
    "\n",
    "- identity (don't do it)\n",
    "- logit \n",
    "    - $logit(\\pi(x)) = \\log\\ds\\frac{\\pi(x)}{1-\\pi(x)} = x'\\beta$ \n",
    "    - in general $\\pi(x)  = F(x'\\beta)$, you can choose $F$ such that$F$ is a cdf on $\\mathbb{R}$ \n",
    "- probit\n",
    "    - $\\pi(x) = \\Phi(x'\\beta)$\n",
    "    - mean = $-\\frac{\\beta_1}{\\beta_2}$ and SD = $\\frac{1}{\\abs{\\beta_2}}$\n",
    "- complimentary-loglog (cloglog)\n",
    "    - $\\pi(x) = 1-\\exp\\bk{-\\exp\\p{x'\\beta}}$\n",
    "    - i.e. $log\\bk{-\\log(1-\\pi(x))} = x'\\beta$, enables skewness\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dose-response Models\n",
    "- bioassays studies\n",
    "    - covariate = dose level (typically on log scale)\n",
    "        - $x_i = (x_1,...,x_n)$, where $n$ is small for practical reasons. Cannot give too many dosees to patient.\n",
    "    - $\\pi(x) = g^{-1}(x^T\\beta)$\n",
    "    - design?\n",
    "    - model / inference (calibration / inversion)\n",
    "    \n",
    "## Forward\n",
    "- fix $x_0$, inference for $\\pi_0$\n",
    "- $\\pi(x) = F(x^T\\beta)$, where $F$ is the CDF on the real line\n",
    "\n",
    "\n",
    "- **Calibration**: inference for unknown dose level $x_0$ that corresponds to a specified $\\pi(x_0)$\n",
    "    - for $\\pi(x_0) = .5 \\rightarrow x_0=LD_{50}$, leathal dose level\n",
    "- **inversion**: inference on uninown dose level $x_0$ that corresponds to a specified $y_0$ and $m_0$.\n",
    "\n",
    "### Specifics\n",
    "- For the calibration problem\n",
    "  - set $q$, then $q = \\pi(x_0) = F({x_0}^T\\beta)$. Then $F^{-1}(q) = {x_0}^T\\beta$. Therefore, you can solve for $x_0$ after fitting the forward model.\n",
    "- inverse\n",
    "  - for new $x_0 \\rightarrow \\text{ fixed } (m_0,y_0)$\n",
    "  - $p(x_0,\\beta | data) \\propto p(x_0)~p(\\beta)~like(\\beta;y,m)~f(y_0;m_0|\\beta,x_0)$\n",
    "  - you can have flat priors for $\\beta$ if you have informative priors for $x_0$\n",
    "  - This is just a missing data problem\n",
    "  - slice sampling:  introduce $u$\n",
    "  $$\n",
    "  \\begin{split}\n",
    "  p(u,x_0|...) &\\propto N(x_0 | a_0+b_0y_0\\beta_2,b_0) \\times \\mathbb{1}(u < \\bk{1+\\exp(\\beta_1+\\beta_2 x_0)}^{-m_0}) \\\\\n",
    "  \\\\\n",
    "  u | x_0 &\\sim  U(0, thatcrapinthebrackets) \\\\\n",
    "  x_0 | u ,... &\\sim TN(a_0 + b_0y_0\\beta_2,b_0) \\mathbb{1}(x_0\\in C) \\\\\n",
    "  \\end{split}\n",
    "  $$\n",
    "  - where $C = (-\\infty,\\frac{-\\beta_1+\\log(u^{-1/m_0}-1)}{\\beta_2})$ if $\\beta_2>0$. Otherwise, $C= (\\frac{-\\beta_1+\\log(u^{-1/m_0}-1)}{\\beta_2},\\infty)$\n",
    "  - The stuff $u$ is less than is a result of the logistic link\n",
    "  - assume $p(x_0) = N(x_0|a_0,b_0)$, well informed $a_0,b_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
